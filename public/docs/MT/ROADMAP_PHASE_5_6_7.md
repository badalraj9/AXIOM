# ğŸ§  THE PERFECT PLAN: PHASES 5, 6, 7 ## (Plans & Instructions Only - No Code)  ---  # ğŸ“‹ PHASE 5: COGNITIVE MAINTENANCE LAYER  **Duration:** 10-12 weeks   **Goal:** Make memory alive - consolidating, pruning, evolving like a real brain  ---  ## ğŸ¯ PHASE 5 ARCHITECTURE OVERVIEW  ``` â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚           COGNITIVE MAINTENANCE                  â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚                                                  â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚ â”‚  â”‚ Identity Serviceâ”‚  â”‚  Assimilator    â”‚     â”‚ â”‚  â”‚ (Merge dupes)   â”‚  â”‚  (Consolidate)  â”‚     â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ â”‚                                                  â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚ â”‚  â”‚     Pruner      â”‚  â”‚  Decay Engine   â”‚     â”‚ â”‚  â”‚ (Remove junk)   â”‚  â”‚  (Age truths)   â”‚     â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ â”‚                                                  â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚ â”‚  â”‚   Maintenance Orchestrator           â”‚      â”‚ â”‚  â”‚   (Schedule jobs, audit, preview)    â”‚      â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ ```  ---  ## ğŸ“¦ PHASE 5.1: IDENTITY SERVICE (Weeks 1-2)  ### **Purpose:** Detect and merge duplicate entities (same person mentioned multiple ways, same concept described differently)  ### **How It Works:**  1. **Detection Phase:**    - Run similarity checks across all entities    - Use embedding cosine similarity (threshold: 0.95+)    - Apply fuzzy string matching on entity names    - Check graph proximity (entities with many shared connections likely same)  2. **Proposal Phase:**    - Generate merge proposals with confidence scores    - Show preview of merged entity    - Explain reasoning ("95% embedding match + 3 shared connections")    - Flag high-risk merges for human review  3. **Execution Phase:**    - Create new merged entity with combined attributes    - Update all references in Layer 2 states    - Mark original entities as "assimilated_into: merged_id"    - Record merge event in Layer 1 (immutable audit trail)    - Update truth vectors (combine corroboration counts)  ### **Key Design Decisions:**  **Question:** What if merge is wrong?   **Answer:** All merges are reversible. Store "split" operation that restores originals.  **Question:** Auto-merge or human approval?   **Answer:**  - Confidence >0.95: Auto-merge (low risk) - Confidence 0.85-0.95: Human approval required - Confidence <0.85: Reject, don't propose  **Question:** How to handle conflicting attributes?   **Answer:** Use truth vector scoring: - Higher authority wins - More recent wins (if authority equal) - More corroborated wins (if tied)  ### **Deliverables:** - `identity_service.py` with detect/propose/execute methods - Merge proposal data structure with confidence + reasoning - Merge event schema (for Layer 1 audit log) - CLI command: `nebula identity scan --entity-type=person` - Dry-run mode that shows proposals without executing  ### **Validation:** - Test case: "John Smith" and "J. Smith" merge correctly - Test case: "Apple Inc" and "Apple (fruit)" do NOT merge - Test case: Merge is reversible (split restores originals) - Benchmark: Can process 10,000 entities in <5 minutes  ---  ## ğŸ“¦ PHASE 5.2: ASSIMILATION ENGINE (Weeks 3-4)  ### **Purpose:** Consolidate micro-events into higher-level summaries (compress "added 10 trees" Ã— 100 events â†’ "added 1000 trees over March")  ### **How It Works:**  1. **Pattern Detection:**    - Find repetitive event sequences on same entity    - Group by time window (daily, weekly, monthly)    - Identify consolidation candidates (similar actions, same object)  2. **Consolidation Rules:**    - **Arithmetic events:** Sum deltas ("+ 10 trees" Ã— 5 â†’ "+ 50 trees")    - **State changes:** Keep only final state if intermediate states unused    - **Repeated facts:** Merge into single fact with increased corroboration    - **Temporal patterns:** "User drinks coffee every morning" â†’ habit pattern  3. **Consolidation Process:**    - Create consolidated event with:      - Aggregated data (sum, count, final state)      - Provenance: list of source event IDs      - Time range covered      - Consolidation method used    - Mark source events as "consolidated_into: new_event_id"    - Keep source events in Layer 1 (never delete)    - Update Layer 2 to reference consolidated event  ### **Key Design Decisions:**  **Question:** When to consolidate?   **Answer:**  - Time-based: After 30 days, consolidate daily events - Volume-based: After 100 similar events - Query-based: If entity has slow replay, consolidate  **Question:** What if need original detail later?   **Answer:** Consolidation is transparent - always trace back to source events via provenance chain  **Question:** How to avoid over-consolidation?   **Answer:** Policy engine with rules: - Never consolidate events from last 7 days (keep recent detail) - Never consolidate events with high importance (>0.9) - Never consolidate if loss of detail impacts queries  ### **Deliverables:** - `assimilator.py` with pattern detection + consolidation logic - Consolidation policy configuration (time windows, rules) - Consolidated event schema (includes provenance array) - CLI: `nebula assimilate --entity-id=X --dry-run` - Before/after report showing size reduction  ### **Validation:** - Test: 100 "add tree" events consolidate to 1 "added 1000 trees" - Test: Provenance chain intact (can trace to all 100 sources) - Test: Replay with consolidated events produces same final state - Benchmark: 50% reduction in working memory size  ---  ## ğŸ“¦ PHASE 5.3: PRUNER (Weeks 5-6)  ### **Purpose:** Remove low-value derived states to keep working memory lean (never touch Layer 1 events!)  ### **How It Works:**  1. **Value Scoring:**    Each derived state (Layer 2) gets pruning score based on:    - **Recency:** Last accessed timestamp    - **Access frequency:** How often queried    - **Importance:** Inherent importance value    - **Uniqueness:** Is this derivable from events?    - **Dependency:** Do other states reference this?  2. **Pruning Rules:**    - Score <0.3: Candidate for pruning    - Not accessed in 90 days: Candidate    - Derivable from events in <100ms: Safe to prune    - No dependents: Safe to prune  3. **Pruning Process:**    - Mark state as "inactive" (soft delete)    - Keep metadata (entity_id, last_known_value, archived_at)    - On future query: Re-derive from Layer 1 if needed    - Periodic cleanup: Actually delete after 1 year  ### **Key Design Decisions:**  **Question:** What if pruned state is needed later?   **Answer:** Re-compute from events. Store "derived_from: [event_ids]" so reconstruction is fast.  **Question:** How to avoid pruning important data?   **Answer:**  - Whitelist: Never prune states with importance >0.8 - Blacklist: Never prune states accessed in last 30 days - Safety: Dry-run shows what would be pruned, requires approval  **Question:** Performance of re-derivation?   **Answer:** Cache recently re-derived states. If state accessed again, keep it active.  ### **Deliverables:** - `pruner.py` with scoring + pruning logic - Pruning policy config (thresholds, whitelists) - Prune event schema (records what was pruned when) - CLI: `nebula prune --dry-run --threshold=0.3` - Recovery mechanism (re-derive on demand)  ### **Validation:** - Test: Low-value states pruned, high-value kept - Test: Pruned state recoverable via re-derivation - Test: No cascading failures (dependencies checked) - Benchmark: 30-50% reduction in active state count  ---  ## ğŸ“¦ PHASE 5.4: DECAY ENGINE (Weeks 7-8)  ### **Purpose:** Truth vectors fade over time - old information becomes less certain (models biological memory decay)  ### **How It Works:**  1. **Decay Curves:**    Different memory types decay at different rates:    - **Facts:** Slow decay (Î» = 0.001/day) - "Paris is capital of France"    - **Preferences:** Medium decay (Î» = 0.01/day) - "User likes coffee"    - **Events:** Fast decay (Î» = 0.1/day) - "User went to store yesterday"    - **Predictions:** Very fast (Î» = 0.5/day) - "User will probably..."  2. **Decay Formula:**    ```    freshness(t) = freshness_0 Ã— e^(-Î» Ã— days_elapsed)        Where:    - freshness_0 = initial freshness (1.0)    - Î» = decay rate (varies by type)    - days_elapsed = time since last reinforcement    ```  3. **Reinforcement:**    - When memory accessed: Reset decay timer    - When corroborated: Increase freshness    - When contradicted: Accelerate decay  4. **Decay Process:**    - Daily job: Update all freshness values    - Compute new truth scores (freshness is factor)    - Memories below threshold (freshness <0.1) marked "stale"    - Stale memories ranked lower in queries  ### **Key Design Decisions:**  **Question:** Do events decay or just truth vectors?   **Answer:** Events never decay (Layer 1 immutable). Only freshness in truth vectors decays.  **Question:** Can decay be reversed?   **Answer:** Yes - accessing memory or new corroboration resets freshness.  **Question:** What about permanent facts?   **Answer:** Set decay rate to 0 for "permanent" memory type (birthdays, identities, etc)  ### **Deliverables:** - `decay_engine.py` with decay curve implementations - Decay policy config (rates per memory type) - Decay computation job (runs daily) - CLI: `nebula decay simulate --days=365` (preview decay) - Decay analytics dashboard (show freshness distribution)  ### **Validation:** - Test: Old preferences decay, recent don't - Test: Accessed memories retain freshness - Test: Decay rates configurable per type - Test: Query ranking reflects decay (old ranked lower)  ---  ## ğŸ“¦ PHASE 5.5: INTEGRATION & ORCHESTRATION (Weeks 9-10)  ### **Purpose:** Coordinate all maintenance operations safely with human oversight  ### **Components:**  1. **Maintenance Scheduler:**    - Daily: Run decay updates    - Weekly: Identity scan (detect duplicates)    - Weekly: Assimilation (consolidate old events)    - Monthly: Pruning pass (remove low-value states)  2. **Dry-Run Mode:**    - Every operation has preview mode    - Shows what WOULD change without changing it    - Generates report: "50 duplicates found, 200 events consolidated, 500 states pruned"  3. **Approval Workflow:**    - High-confidence operations: Auto-execute    - Medium-confidence: Queue for approval    - Low-confidence: Reject, log for review    - Human can approve/reject/modify proposals  4. **Audit & Rollback:**    - Every maintenance action is Layer 1 event    - Can query: "Show all merges in last month"    - Can rollback: "Undo merge of entity X and Y"    - Maintains integrity even if operations fail  ### **Deliverables:** - `maintenance_orchestrator.py` (job scheduler) - Approval queue database table - Rollback operations (split, unprune, restore) - CLI: `nebula maintenance schedule --enable=all` - Dashboard showing pending approvals  ### **Validation:** - Test: Scheduled jobs run on time - Test: Dry-run accurate (matches actual results) - Test: Approval workflow functional - Test: Rollback restores previous state  ---  ## ğŸ“¦ PHASE 5.6: HUMAN-IN-LOOP UI (Weeks 11-12)  ### **Purpose:** Give user control and visibility into maintenance operations  ### **Features:**  1. **Maintenance Dashboard:**    - Show active maintenance jobs    - Display pending approvals    - Visualize memory health metrics:      - Total entities      - Duplicate clusters detected      - Consolidation opportunities      - States marked for pruning      - Average freshness score  2. **Proposal Review UI:**    - List merge proposals with confidence    - Side-by-side comparison of entities to merge    - Explanation of why merge proposed    - Preview merged result    - Approve/reject/defer buttons  3. **Maintenance History:**    - Timeline of all operations    - Filter by type (merge, prune, consolidate, decay)    - Rollback button for recent operations    - Export audit log  4. **Configuration UI:**    - Adjust decay rates per memory type    - Set pruning thresholds    - Configure consolidation windows    - Enable/disable auto-approval  ### **Deliverables:** - Web UI for maintenance dashboard (React/Vue/Svelte) - API endpoints for UI (GET /proposals, POST /approve, etc) - Real-time updates (WebSocket for job progress) - Mobile-responsive design  ### **Validation:** - User can review and approve merge - User can rollback operation - User can adjust thresholds - UI reflects actual system state  ---  # ğŸ“‹ PHASE 6: COGNITIVE CORRECTNESS LAYER  **Duration:** 10-12 weeks   **Goal:** Prove system is correct and can run reliably for 20+ years  ---  ## ğŸ¯ PHASE 6 ARCHITECTURE OVERVIEW  ``` â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚        CORRECTNESS & RELIABILITY                 â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚                                                  â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚ â”‚  â”‚ Replay Debugger â”‚  â”‚ Snapshot Managerâ”‚     â”‚ â”‚  â”‚ (Verify state)  â”‚  â”‚ (Compress)      â”‚     â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ â”‚                                                  â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚ â”‚  â”‚ Ancestry Cache  â”‚  â”‚ Timewarp Engine â”‚     â”‚ â”‚  â”‚ (Fast replay)   â”‚  â”‚ (Late events)   â”‚     â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ â”‚                                                  â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚ â”‚  â”‚   Integrity Checker (CI/CD)          â”‚      â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ ```  ---  ## ğŸ“¦ PHASE 6.1: DETERMINISTIC REPLAY DEBUGGER (Weeks 1-3)  ### **Purpose:** Prove that replaying events produces exactly the same state (catch bugs in TMS logic)  ### **How It Works:**  1. **Capture Mode:**    - Record full event sequence for an entity    - Capture initial state Sâ‚€    - Capture final state S_final    - Save as "golden trace" (test fixture)  2. **Replay Mode:**    - Load golden trace    - Start from Sâ‚€    - Replay all events through TMS    - Compare result to S_final  3. **Divergence Detection:**    - Field-by-field comparison    - Highlight differences    - Show which event caused divergence    - Generate bug report  4. **Regression Testing:**    - CI/CD runs replay on every code change    - Collection of golden traces (10-100 entities)    - Any divergence = build fails  ### **Key Features:**  **Visual Diff:** ``` Expected (Golden):   entity.tree_count = 4990   entity.truth_vector.freshness = 0.95  Actual (Replay):   entity.tree_count = 4990 âœ“   entity.truth_vector.freshness = 0.87 âœ—  Diverged at: Event #47 (DECAY_UPDATE) Reason: Decay rate changed from 0.01 to 0.015 ```  **Time-Travel Debugging:** - Step through events one by one - Inspect state after each event - Compare to expected at each step - Identify exact moment of divergence  **Bulk Validation:** - Test 100+ entities in parallel - Pass/fail summary - Detailed report for failures only  ### **Deliverables:** - `replay_debugger.py` (capture + replay + diff) - Golden trace format (JSON with events + states) - CLI: `nebula replay test --trace=entity_123.json` - CI job: `test_replay_regression.sh` - HTML diff report (visual comparison)  ### **Validation:** - All current golden traces pass replay - Modified TMS logic caught by replay failure - Divergence location accurately identified - Regression tests complete in <10 minutes  ---  ## ğŸ“¦ PHASE 6.2: SNAPSHOT COMPACTION (Weeks 4-6)  ### **Purpose:** Enable instant replay even with millions of events (snapshot + delta instead of full replay)  ### **How It Works:**  1. **Snapshot Creation:**    - Periodic job (daily, weekly): capture entity state snapshots    - Store: `{entity_id, timestamp, full_state, event_id_at_snapshot}`    - Compress: Use efficient binary format (msgpack, protobuf)  2. **Incremental Storage:**    ```    Entity timeline:        Sâ‚€ â”€â”€â”€â”€â†’ [events 1-1000] â”€â”€â”€â”€â†’ Snapshotâ‚ â”€â”€â”€â”€â†’ [events 1001-2000] â”€â”€â”€â”€â†’ Snapshotâ‚‚        To get current state:    - Load Snapshotâ‚‚ (instant)    - Replay only events 2001-current (fast)        Instead of:    - Replay all 10,000 events (slow)    ```  3. **Compaction Strategy:**    - Keep hourly snapshots for last week    - Keep daily snapshots for last month    - Keep weekly snapshots for last year    - Keep monthly snapshots forever  4. **Snapshot Validation:**    - Periodically verify: snapshot + replay = full replay    - Flag corrupted snapshots    - Auto-regenerate if invalid  ### **Key Design Decisions:**  **Question:** How often to snapshot?   **Answer:**  - Hot entities (frequently queried): Hourly - Warm entities: Daily - Cold entities (rarely accessed): Weekly or on-demand  **Question:** Storage cost?   **Answer:**  - Compress snapshots (50-80% size reduction) - Deduplicate common fields - Prune old snapshots per retention policy  **Question:** Snapshot during maintenance?   **Answer:** After consolidation/pruning, take new snapshot (reflects compacted state)  ### **Deliverables:** - `snapshot_manager.py` (create/load/validate/compact) - Snapshot storage format (compressed binary) - Snapshot job scheduler - CLI: `nebula snapshot create --entity=X` - CLI: `nebula snapshot restore --entity=X --time=yesterday`  ### **Validation:** - Snapshot + replay = full replay (bit-exact) - Load time <100ms for typical entity - Storage overhead <20% of event log size - Corruption detected and auto-fixed  ---  ## ğŸ“¦ PHASE 6.3: EVENT ANCESTRY OPTIMIZER (Weeks 7-8)  ### **Purpose:** Make replay fast by caching causal chains (don't recompute "what events led to this state" every time)  ### **How It Works:**  1. **Ancestry Fingerprint:**    Instead of storing full causal DAG:    ```    Event Eâ‚â‚€â‚€ depends on:    â”œâ”€ Eâ‚‰â‚‰ â†’ Eâ‚‰â‚… â†’ Eâ‚ˆâ‚€ â†’ Eâ‚…â‚€ â†’ Eâ‚    â”œâ”€ Eâ‚‰â‚ˆ â†’ Eâ‚‰â‚€ â†’ Eâ‚‡â‚€    â””â”€ Eâ‚‰â‚‡ â†’ Eâ‚ˆâ‚…        Store fingerprint: Hash([Eâ‚, Eâ‚…â‚€, Eâ‚‡â‚€, Eâ‚ˆâ‚€, Eâ‚ˆâ‚…, Eâ‚‰â‚€, Eâ‚‰â‚…, Eâ‚‰â‚‡, Eâ‚‰â‚ˆ, Eâ‚‰â‚‰])    ```  2. **Collapsed Chains:**    - Cache common ancestry paths    - Example: "All events 1-100" â†’ single fingerprint    - On replay: check fingerprint instead of walking graph  3. **Incremental Updates:**    - When new event added:      - Compute its ancestry (parent events)      - Merge with cached fingerprints      - Update cached paths  4. **Query Optimization:**    ```    Question: "What events caused tree_count=4990?"        Without cache:    - Walk entire DAG (1000s of events)    - Follow all causal edges    - Build full provenance    Time: 500ms        With cache:    - Load fingerprint    - Decompress to event IDs    - Return instantly    Time: 5ms    ```  ### **Key Design Decisions:**  **Question:** When to rebuild cache?   **Answer:**  - Incrementally on new events (fast) - Full rebuild daily (catch any drift) - On-demand if corruption detected  **Question:** Cache invalidation?   **Answer:** Fingerprints are immutable (events are immutable). Only add new, never invalidate old.  **Question:** Memory vs disk?   **Answer:**  - Hot fingerprints in RAM (LRU cache) - Cold fingerprints on disk (load on demand)  ### **Deliverables:** - `ancestry_cache.py` (fingerprint + query) - Cache storage (Redis or local) - Fingerprint update job (on new events) - CLI: `nebula ancestry rebuild` - Benchmark showing speedup  ### **Validation:** - Cached ancestry = full DAG walk (correctness) - Query speedup 10-100x (performance) - Cache hit rate >90% on typical queries - No memory leaks (bounded cache size)  ---  ## ğŸ“¦ PHASE 6.4: TIMEWARP CORRECTION (Weeks 9-10)  ### **Purpose:** Handle late-arriving events efficiently (event timestamped in past arrives now)  ### **Problem:** ``` Timeline: Jan 1: Event A (tree_count = 5000) Jan 15: Event B (tree_count = 5010) Jan 30: Current state (tree_count = 5010)  NEW EVENT ARRIVES: Jan 10: Event C (tree_count = 4990) â† OUT OF ORDER!  Naive solution: Replay ALL events from Jan 1 Problem: Expensive if 10,000 events after Jan 10 ```  ### **Smart Solution:**  1. **Affected Entity Detection:**    - Identify which entities late event touches    - Only recompute THOSE entities    - Other entities unaffected  2. **Partial Replay:**    ```    Late event at timestamp T:        - Load snapshot BEFORE T    - Replay events from T to now (only for affected entity)    - Merge result with current state    - Detect conflicts (if any)    ```  3. **Conflict Resolution:**    If late event contradicts current state:    - Compare truth vectors    - Higher authority/fresher wins    - Record conflict in Layer 0 (meta-stability)  4. **Incremental Correction:**    - Insert late event in Layer 1    - Mark affected states "needs_recompute"    - Background job fixes them lazily    - Queries get "stale warning" until fixed  ### **Key Design Decisions:**  **Question:** How far back can late events go?   **Answer:**  - Accept events up to 30 days late - Older than 30 days: Require manual approval - Beyond 1 year: Reject (too disruptive)  **Question:** What if late event changes critical decision?   **Answer:** Flag as high-severity correction, require human review  **Question:** Performance cost?   **Answer:** Lazy recomputation means cost spread over time, not immediate spike  ### **Deliverables:** - `timewarp_engine.py` (insert + recompute) - Conflict detection logic - Lazy recomputation job - CLI: `nebula timewarp insert --event=late_event.json` - Report: "3 entities affected, 1 conflict detected"  ### **Validation:** - Late event correctly inserted in timeline - Only affected entities recomputed - Conflicts detected and flagged - System remains consistent  ---  ## ğŸ“¦ PHASE 6.5: CI/CD INTEGRATION (Weeks 11-12)  ### **Purpose:** Automate correctness testing - every code change must pass replay tests  ### **CI Pipeline:**  ``` 1. Code commit    â†“ 2. Unit tests (fast - 2 min)    â†“ 3. Integration tests (medium - 10 min)    â†“ 4. Replay regression tests (slow - 30 min)    - Load 100 golden traces    - Replay each    - Assert bit-exact results    â†“ 5. If any fail: Block merge    â†“ 6. If pass: Allow merge ```  ### **Golden Trace Library:**  Maintain diverse test cases: - Simple entity (10 events) - Complex entity (1000 events) - Merge scenario (duplicate entities) - Consolidation scenario (assimilated events) - Decay scenario (truth vectors fading) - Conflict scenario (contradictory events) - Late-arrival scenario (timewarp)  ### **Nightly Jobs:**  Beyond PR checks: - Full system replay (all entities) - Snapshot validation (recompute from scratch, compare) - Integrity checks (no orphaned references) - Performance benchmarks (track regression)  ### **Deliverables:** - GitHub Actions / GitLab CI config - Golden trace repository (tests/golden/) - Replay test runner script - Nightly job configuration - Performance tracking dashboard  ### **Validation:** - CI catches TMS bugs before merge - Golden traces cover edge cases - Nightly jobs report daily - Performance tracked over time  ---  # ğŸ“‹ PHASE 7: KNOWLEDGE GRAPH & MULTI-HOP REASONING  **Duration:** 10-12 weeks   **Goal:** Add structured relationships so Nebula can answer "why" and "how" questions  ---  ## ğŸ¯ PHASE 7 ARCHITECTURE OVERVIEW  ``` â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚         KNOWLEDGE GRAPH REASONING                â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚                                                  â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚  â”‚         Graph Database                   â”‚   â”‚ â”‚  â”‚  (Entities + Relations + Attributes)     â”‚   â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚                    â†“                             â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚  â”‚      Multi-Hop Query Engine              â”‚   â”‚ â”‚  â”‚  (Path finding, reasoning chains)        â”‚   â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚                    â†“                             â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚  â”‚      Hybrid Retrieval                    â”‚   â”‚ â”‚  â”‚  Vector search â†’ Graph filter â†’ Rerank   â”‚   â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚                                                  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ ```  ---  ## ğŸ“¦ PHASE 7.1: GRAPH DATABASE FOUNDATION (Weeks 1-3)  ### **Purpose:** Store structured relationships between entities (not just embeddings)  ### **Data Model:**  **Entities (Nodes):** ``` {   "id": "entity_123",   "type": "person | concept | event | place",   "name": "Alice",   "attributes": {...},   "truth_vector": [C, A, F, R] } ```  **Relations (Edges):** ``` {   "from_entity": "entity_123",   "relation_type": "works_at | knows | located_in | caused_by",   "to_entity": "entity_456",   "confidence": 0.95,   "first_seen": "2025-01-01",   "last_confirmed": "2025-06-01" } ```  **Relation Types:**  Common patterns: - **Hierarchical:** "is_a", "part_of", "belongs_to" - **Temporal:** "happened_before", "caused", "resulted_in" - **Social:** "knows", "friend_of", "works_with" - **Spatial:** "located_in", "near", "adjacent_to" - **Semantic:** "similar_to", "opposite_of", "related_to"  ### **Storage Options:**  **Option A:** PostgreSQL with recursive CTEs - Pros: Already have Postgres, familiar - Cons: Not optimized for deep graph queries  **Option B:** Neo4j or specialized graph DB - Pros: Optimized for graph traversal - Cons: Another database to manage  **Option C:** Hybrid (Postgres + in-memory graph) - Pros: Best of both worlds - Cons: Complexity  **Recommendation:** Start with Postgres, migrate to Neo4j if queries slow  ### **Graph Construction:**  Extract relations from: 1. **Explicit statements:** "Alice works at Company X" 2. **Co-occurrence:** Entities mentioned together frequently 3. **Temporal proximity:** Events close in time may be related 4. **Embedding similarity:** Similar entities likely related  ### **Deliverables:** - Graph schema (entities + relations tables) - Graph construction job (extract relations from events) - Graph query API (find paths, get neighbors) - CLI: `nebula graph show --entity=alice --depth=2`  ### **Validation:** - Common relations extracted correctly - Graph query returns expected paths - No orphaned nodes (all entities reachable)  ---  ## ğŸ“¦ PHASE 7.2: MULTI-HOP QUERY ENGINE (Weeks 4-6)  ### **Purpose:** Answer questions requiring multiple reasoning steps  ### **Query Types:**  **1. Path Finding:** ``` Question: "How is Alice connected to Bob?"  Query: Find path(alice, bob, max_hops=5)  Result: alice â†’ works_at â†’ CompanyX â†’ located_in â†’ CityY â†’ home_of â†’ bob  Confidence: 0.85 (product of edge confidences) ```  **2. Common Connections:** ``` Question: "What do Alice and Bob have in common?"  Query: Find common_neighbors(alice, bob)  Result: - Both work_at CompanyX - Both know Charlie - Both interested_in AI ```  **3. Transitive Relations:** ``` Question: "Who are Alice's colleagues?"  Query: Find transitive(alice, works_with, depth=2)  Result: - Direct colleagues (1 hop) - Colleagues of colleagues (2 hops) ```  **4. Temporal Chains:** ``` Question: "What events led to the forest fire?"  Query: Find causal_chain(forest_fire, max_depth=10)  Result: drought â†’ dry_conditions â†’ lightning_strike â†’ forest_fire ```  ### **Query Optimization:**  **Bounded Depth:** - Limit hops to 3-5 (prevent expensive queries) - Warn if no path found within limit  **Caching:**- Cache common paths (e.g., alice â†’ bob) - Invalidate when graph changes  **Pruning:** - Stop following low-confidence edges (<0.5) - Prefer high-truth-score paths  **Bidirectional Search:** - Search from both ends simultaneously - Meet in middle (faster for long paths)  ### **Deliverables:** - Multi-hop query engine (BFS, DFS, bidirectional) - Path scoring algorithm (confidence product) - Query optimizer (caching, pruning) - CLI: `nebula graph path --from=alice --to=bob` - API: `GET /graph/path?from=X&to=Y&max_hops=5`  ### **Validation:** - Known paths found correctly - Path confidence scores reasonable - Query completes in <500ms (typical) - No infinite loops in cyclic graphs  ---  ## ğŸ“¦ PHASE 7.3: HYBRID RETRIEVAL ENGINE (Weeks 7-9)  ### **Purpose:** Combine vector search (semantic) with graph constraints (structured) for better accuracy  ### **Pipeline:**  ``` Question: "Tell me about Alice's work in AI"  Step 1: VECTOR SEARCH (Qdrant) â†“ Candidates: [doc1, doc2, doc3, ..., doc100] (All semantically related to "Alice" and "AI")  Step 2: GRAPH FILTERING (Postgres) â†“ Filter by: - Must mention entity: alice - Must be connected to: AI concepts - Must have relation: works_on â†“ Filtered: [doc2, doc15, doc47]  Step 3: RERANKING (Truth Vectors) â†“ Sort by: - Truth score (C Ã— A Ã— F Ã— log(R)) - Recency - Relevance â†“ Final results: [doc47, doc2, doc15] ```  ### **Why This Works:**  **Vector-only problems:** - "Alice" might match "Allison" (similar embeddings) - Can't enforce "must be about work" constraint - No way to prefer authoritative sources  **Graph-only problems:** - Misses semantic similarity - Requires exact relation matches - Can't handle ambiguous queries  **Hybrid solution:** - Vector: Recall (find candidates) - Graph: Precision (filter irrelevant) - Truth: Ranking (prioritize quality)  ### **Advanced Features:**  **Faceted Search:** ``` Question: "AI research by people at Stanford"  Facets: - entity_type: person - relation: affiliated_with â†’ Stanford - topic: AI research  Results filtered by all facets simultaneously ```  **Temporal Constraints:** ``` Question: "What did Alice work on last year?"  Time filter: - timestamp between 2024-01-01 and 2024-12-31 - entity: alice - relation: works_on ```  **Provenance Tracing:** ``` For each result, show: - Why matched (vector similarity: 0.92) - Graph path (alice â†’ works_on â†’ project_X) - Truth score (0.87) - Sources (3 corroborating events) ```  ### **Deliverables:** - Hybrid retrieval pipeline (vector + graph + truth) - Query planner (optimizes search strategy) - Faceted search API - Provenance formatter (explains results) - Benchmarks (accuracy improvement vs vector-only)  ### **Validation:** - Hybrid > vector-only (precision@10) - Graph constraints reduce false positives - Queries complete in <100ms (P95) - Provenance always available  ---  ## ğŸ“¦ PHASE 7.4: REASONING PATTERNS (Weeks 10-12)  ### **Purpose:** Teach Nebula common reasoning patterns (analogies, contradictions, implications)  ### **Pattern Library:**  **1. Transitivity:** ``` If: A works_at B And: B part_of C Then: A affiliated_with C (inferred) ```  **2. Symmetry:** ``` If: A friend_of B Then: B friend_of A (inferred) ```  **3. Inverse Relations:** ``` If: A parent_of B Then: B child_of A (inferred) ```  **4. Contradiction Detection:** ``` If: A located_in B And: A located_in C And: B != C Then: CONFLICT (entity can't be in two places) ```  **5. Temporal Reasoning:** ``` If: Event A happened_before Event B And: Event B happened_before Event C Then: Event A happened_before Event C (transitivity) ```  **6. Causal Inference:** ``` If: A caused B (confidence: 0.9) And: B caused C (confidence: 0.8) Then: A may_have_caused C (confidence: 0.72) ```  ### **Implementation:**  **Rule Engine:** - Define rules in declarative format - Apply rules during graph construction - Infer new relations automatically - Mark inferred relations (vs. explicit)  **Example Rule:** ```yaml rule: transitive_workplace pattern:   - ?person works_at ?company   - ?company part_of ?parent_company infer:   - ?person affiliated_with ?parent_company confidence: 0.8 ```  **Conflict Detection:** ```yaml rule: single_location pattern:   - ?entity located_in ?place1   - ?entity located_in ?place2   - ?place1 != ?place2 action: flag_contradiction severity: medium ```  ### **Deliverables:** - Rule engine (pattern matching + inference) - Rule library (20-30 common patterns) - Conflict detector (flags contradictions) - Inferred relation marker (distinguish from explicit) - CLI: `nebula graph infer --entity=alice`  ### **Validation:** - Transitive relations correctly inferred - Contradictions detected - Inferred relations marked appropriately - No infinite inference loops  ---  # ğŸ“Š PHASE COMPLETION CRITERIA  ## Phase 5 Complete When: - [ ] Identity merging works with >95% accuracy - [ ] Assimilation reduces memory by 30-50% - [ ] Pruning removes low-value states safely - [ ] Decay curves implemented and configurable - [ ] All operations auditable and reversible - [ ] Human-in-loop UI functional  ## Phase 6 Complete When: - [ ] Replay tests pass on 100+ golden traces - [ ] Snapshots enable <100ms state loading - [ ] Ancestry cache speeds up queries 10x+ - [ ] Timewarp handles late events correctly - [ ] CI/CD catches regressions automatically - [ ] System provably correct  ## Phase 7 Complete When: - [ ] Graph stores entities + relations - [ ] Multi-hop queries work (3-5 hops) - [ ] Hybrid retrieval beats vector-only - [ ] Reasoning patterns infer relations - [ ] Provenance always available - [ ] Queries complete in <500ms  ---  # ğŸ¯ EXECUTION ORDER  **Priority 1:** Phase 5 (Makes memory alive)   **Priority 2:** Phase 6 (Makes memory reliable)   **Priority 3:** Phase 7 (Makes memory smart)  **Timeline:** - Months 1-3: Phase 5 - Months 4-6: Phase 6   - Months 7-9: Phase 7  **After Phase 7:** You have a genuinely intelligent, reliable, living memory system that no competitor has.  ---  **This is your roadmap. Execute it.** ğŸš€